{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hazm import (\n",
    "    Normalizer, word_tokenize, POSTagger,\n",
    "    Chunker, tree2brackets, Lemmatizer,\n",
    "    DependencyParser, Stemmer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1384003, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>poemId</th>\n",
       "      <th>order</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>جز نقش تو در نظر نیامد ما را</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2051</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>جز کوی تو رهگذر نیامد ما را</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2051</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>خواب ارچه خوش آمد همه را در عهدت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2051</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>حقا که به چشم در نیامد ما را</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2052</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>بر گیر شراب طرب‌انگیز و بیا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  poemId  order  position                              text\n",
       "0   1    2051      1         0      جز نقش تو در نظر نیامد ما را\n",
       "1   2    2051      2         1       جز کوی تو رهگذر نیامد ما را\n",
       "2   3    2051      3         0  خواب ارچه خوش آمد همه را در عهدت\n",
       "3   4    2051      4         1      حقا که به چشم در نیامد ما را\n",
       "4   5    2052      1         0       بر گیر شراب طرب‌انگیز و بیا"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data - seprate by ;\n",
    "df = pd.read_csv('data/verses.csv', sep=';')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial normalizer, lemmatizer, stemmer\n",
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stemmer = Stemmer()\n",
    "chunker = Chunker(model='resources/chunker.model')\n",
    "tagger = POSTagger(model='resources/postagger.model')\n",
    "parser = DependencyParser(tagger=tagger, lemmatizer=lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "verses = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "original_verse:  جز نقش تو در نظر نیامد ما را\n",
      "normalized_verse:  جز نقش تو در نظر نیامد ما را\n",
      "tokens:  ['جز', 'نقش', 'تو', 'در', 'نظر', 'نیامد', 'ما', 'را']\n",
      "tagged:  [('جز', 'P'), ('نقش', 'Ne'), ('تو', 'PRO'), ('در', 'P'), ('نظر', 'N'), ('نیامد', 'V'), ('ما', 'PRO'), ('را', 'POSTP')]\n",
      "================================\n",
      "original_verse:  جز کوی تو رهگذر نیامد ما را\n",
      "normalized_verse:  جز کوی تو رهگذر نیامد ما را\n",
      "tokens:  ['جز', 'کوی', 'تو', 'رهگذر', 'نیامد', 'ما', 'را']\n",
      "tagged:  [('جز', 'P'), ('کوی', 'Ne'), ('تو', 'PRO'), ('رهگذر', 'N'), ('نیامد', 'V'), ('ما', 'PRO'), ('را', 'POSTP')]\n",
      "================================\n",
      "original_verse:  خواب ارچه خوش آمد همه را در عهدت\n",
      "normalized_verse:  خواب ارچه خوش آمد همه را در عهدت\n",
      "tokens:  ['خواب', 'ارچه', 'خوش', 'آمد', 'همه', 'را', 'در', 'عهدت']\n",
      "tagged:  [('خواب', 'N'), ('ارچه', 'ADV'), ('خوش', 'AJ'), ('آمد', 'V'), ('همه', 'PRO'), ('را', 'POSTP'), ('در', 'P'), ('عهدت', 'N')]\n",
      "================================\n",
      "original_verse:  حقا که به چشم در نیامد ما را\n",
      "normalized_verse:  حقا که به چشم در نیامد ما را\n",
      "tokens:  ['حقا', 'که', 'به', 'چشم', 'در', 'نیامد', 'ما', 'را']\n",
      "tagged:  [('حقا', 'ADV'), ('که', 'CONJ'), ('به', 'P'), ('چشم', 'N'), ('در', 'P'), ('نیامد', 'V'), ('ما', 'PRO'), ('را', 'POSTP')]\n",
      "================================\n",
      "original_verse:  بر گیر شراب طرب‌انگیز و بیا\n",
      "normalized_verse:  بر گیر شراب طرب‌انگیز و بیا\n",
      "tokens:  ['بر', 'گیر', 'شراب', 'طرب\\u200cانگیز', 'و', 'بیا']\n",
      "tagged:  [('بر', 'P'), ('گیر', 'Ne'), ('شراب', 'Ne'), ('طرب\\u200cانگیز', 'AJ'), ('و', 'CONJ'), ('بیا', 'V')]\n",
      "================================\n",
      "original_verse:  پنهان ز رقیب سفله بستیز و بیا\n",
      "normalized_verse:  پنهان ز رقیب سفله بستیز و بیا\n",
      "tokens:  ['پنهان', 'ز', 'رقیب', 'سفله', 'بستیز', 'و', 'بیا']\n",
      "tagged:  [('پنهان', 'AJ'), ('ز', 'Pe'), ('رقیب', 'Ne'), ('سفله', 'Ne'), ('بستیز', 'AJ'), ('و', 'CONJ'), ('بیا', 'V')]\n",
      "================================\n",
      "original_verse:  مشنو سخن خصم که بنشین و مرو\n",
      "normalized_verse:  مشنو سخن خصم که بنشین و مرو\n",
      "tokens:  ['مشنو', 'سخن', 'خصم', 'که', 'بنشین', 'و', 'مرو']\n",
      "tagged:  [('مشنو', 'N'), ('سخن', 'Ne'), ('خصم', 'N'), ('که', 'CONJ'), ('بنشین', 'V'), ('و', 'CONJ'), ('مرو', 'N')]\n",
      "================================\n",
      "original_verse:  بشنو ز من این نکته که برخیز و بیا\n",
      "normalized_verse:  بشنو ز من این نکته که برخیز و بیا\n",
      "tokens:  ['بشنو', 'ز', 'من', 'این', 'نکته', 'که', 'برخیز', 'و', 'بیا']\n",
      "tagged:  [('بشنو', 'V'), ('ز', 'Pe'), ('من', 'PRO'), ('این', 'DET'), ('نکته', 'N'), ('که', 'CONJ'), ('برخیز', 'V'), ('و', 'CONJ'), ('بیا', 'V')]\n",
      "================================\n",
      "original_verse:  گفتم که لبت، گفت لبم آب حیات\n",
      "normalized_verse:  گفتم که لبت، گفت لبم آب حیات\n",
      "tokens:  ['گفتم', 'که', 'لبت', '،', 'گفت', 'لبم', 'آب', 'حیات']\n",
      "tagged:  [('گفتم', 'V'), ('که', 'CONJ'), ('لبت', 'N'), ('،', 'PUNC'), ('گفت', 'V'), ('لبم', 'N'), ('آب', 'Ne'), ('حیات', 'N')]\n",
      "================================\n",
      "original_verse:  گفتم دهنت، گفت زهی حب نبات\n",
      "normalized_verse:  گفتم دهنت، گفت زهی حب نبات\n",
      "tokens:  ['گفتم', 'دهنت', '،', 'گفت', 'زهی', 'حب', 'نبات']\n",
      "tagged:  [('گفتم', 'V'), ('دهنت', 'N'), ('،', 'PUNC'), ('گفت', 'V'), ('زهی', 'N'), ('حب', 'Ne'), ('نبات', 'N')]\n"
     ]
    }
   ],
   "source": [
    "# get structure of first 10 verses\n",
    "for verse in verses[:10]:\n",
    "    normalized_verse = normalizer.normalize(verse)\n",
    "    tokens = word_tokenize(normalized_verse)\n",
    "    tagged = tagger.tag(tokens)\n",
    "    # parsed = parser.parse(tagged)\n",
    "    print(\"================================\")\n",
    "    print(\"original_verse: \", verse)\n",
    "    print(\"normalized_verse: \", normalized_verse)\n",
    "    print(\"tokens: \", tokens)\n",
    "    print(\"tagged: \", tagged)\n",
    "    # print(\"parsed: \", parsed)\n",
    "    # print(tree2brackets(chunker.parse(tagged)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# categorize tokens\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m verse \u001b[38;5;129;01min\u001b[39;00m verses:\n\u001b[0;32m----> 4\u001b[0m     normalized_verse \u001b[38;5;241m=\u001b[39m \u001b[43mnormalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m word_tokenize(normalized_verse)\n\u001b[1;32m      6\u001b[0m     tagged \u001b[38;5;241m=\u001b[39m tagger\u001b[38;5;241m.\u001b[39mtag(tokens)\n",
      "File \u001b[0;32m~/.virtualenvs/poet/lib/python3.10/site-packages/hazm/Normalizer.py:74\u001b[0m, in \u001b[0;36mNormalizer.normalize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 74\u001b[0m \ttext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharacter_refinement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_affix_spacing:\n\u001b[1;32m     76\u001b[0m \t\ttext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maffix_spacing(text)\n",
      "File \u001b[0;32m~/.virtualenvs/poet/lib/python3.10/site-packages/hazm/Normalizer.py:103\u001b[0m, in \u001b[0;36mNormalizer.character_refinement\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcharacter_refinement\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m     88\u001b[0m \t\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m\t>>> normalizer = Normalizer()\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m\t>>> normalizer.character_refinement('اصلاح كاف و ياي عربي')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\t'بشقاب من را بگیر'\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \ttext \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslations)\n\u001b[1;32m    104\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m pattern, repl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharacter_refinement_patterns:\n\u001b[1;32m    105\u001b[0m \t\ttext \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39msub(repl, text)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'translate'"
     ]
    }
   ],
   "source": [
    "categories = {}\n",
    "# categorize tokens\n",
    "for verse in verses:\n",
    "    normalized_verse = normalizer.normalize(verse)\n",
    "    tokens = word_tokenize(normalized_verse)\n",
    "    tagged = tagger.tag(tokens)\n",
    "    # add to categories\n",
    "    for token in tagged:\n",
    "        print(token)\n",
    "        if token[1] not in categories:\n",
    "            categories[token[1]] = [token[0]]\n",
    "        else:\n",
    "            categories.get(token[1]).append(token[0])\n",
    "\n",
    "print(len(categories))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50fc4a9833fff01f39a5af68154147935adff8dd6b3cc625641ca32fe6e833cf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('poet': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
